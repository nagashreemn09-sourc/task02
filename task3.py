# -*- coding: utf-8 -*-
"""Task3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Gppw7nPdL0cazxml4c1JoP9biyB4BtJ
"""

# Full end-to-end Decision Tree pipeline for Bank Marketing (sklearn)
import pandas as pd
import numpy as np
import joblib  # For saving the model

from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

# Load your dataset
# df = pd.read_csv('/content/bank-additional-full.csv')  # Uncomment and set your dataset path
# For the purpose of this example, let's create a dummy DataFrame
data = {
    'age': [30, 40, 35, 50, 23, 45, 36, 29],
    'job': ['admin.', 'technician', 'blue-collar', 'student', 'admin.', 'technician', 'blue-collar', 'student'],
    'marital': ['single', 'married', 'single', 'single', 'married', 'single', 'married', 'single'],
    'education': ['high.school', 'university.degree', 'high.school', 'university.degree',
                  'high.school', 'university.degree', 'high.school', 'university.degree'],
    'y': [0, 1, 0, 1, 0, 1, 0, 1]  # Target variable
}

df = pd.DataFrame(data)

# Define features and target
X = df.drop('y', axis=1)
y = df['y']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Define categorical and numerical columns
categorical_cols = ['job', 'marital', 'education']
numerical_cols = ['age']

# Create a preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ]), numerical_cols),
        ('cat', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ]), categorical_cols)
    ])

# Create the Decision Tree pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', DecisionTreeClassifier(random_state=42))
])

# Set up hyperparameter tuning using GridSearchCV
param_grid = {
    'classifier__max_depth': [None, 5, 10],
    'classifier__min_samples_split': [2, 5, 10],
}

grid_search = GridSearchCV(pipeline, param_grid, cv=StratifiedKFold(n_splits=5), scoring='accuracy')
grid_search.fit(X_train, y_train)

# Best model
best_model = grid_search.best_estimator_

# Evaluate the model
test_accuracy = best_model.score(X_test, y_test)
print(f'Test Accuracy: {test_accuracy:.2f}')

# Save the model
joblib.dump(best_model, 'bank_dt_pipeline.pkl')
print("Saved model to bank_dt_pipeline.pkl")

# Optional: Visualize the Decision Tree
plt.figure(figsize=(12, 8))
plot_tree(best_model.named_steps['classifier'], filled=True, feature_names=X.columns, class_names=['No', 'Yes'])
plt.title('Decision Tree Visualization')
plt.show()